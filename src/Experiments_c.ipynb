{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:01:31.698097200Z",
     "start_time": "2023-10-23T21:01:31.688006200Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "train_c = pd.read_parquet('./data/C/train_targets.parquet')\n",
    "\n",
    "X_train_estimated_c = pd.read_parquet('./data/C/X_train_estimated.parquet')\n",
    "X_train_observed_c = pd.read_parquet('./data/C/X_train_observed.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('./data/C/X_test_estimated.parquet')\n",
    "\n",
    "X_test_estimated_c['date_forecast'] = pd.to_datetime(X_test_estimated_c['date_forecast'])\n",
    "X_test_estimated_c = X_test_estimated_c[X_test_estimated_c['date_forecast'].dt.minute == 0]\n",
    "\n",
    "df = pd.concat([X_train_observed_c, X_train_estimated_c])\n",
    "df = pd.merge(df, train_c, left_on='date_forecast', right_on='time', how='inner')\n",
    "df = df.drop(columns=['date_forecast', 'date_calc', 'snow_density:kgm3', 'snow_drift:idx', 'fresh_snow_1h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'fresh_snow_24h:cm'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:01:31.744123700Z",
     "start_time": "2023-10-23T21:01:31.700098100Z"
    }
   },
   "id": "38e3782c592de7d1"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_test_estimated_c[['ceiling_height_agl:m', 'cloud_base_agl:m']] = imputer.fit_transform(X_test_estimated_c[['ceiling_height_agl:m', 'cloud_base_agl:m']])\n",
    "df[['ceiling_height_agl:m', 'cloud_base_agl:m', 'pv_measurement']] = imputer.fit_transform(df[['ceiling_height_agl:m', 'cloud_base_agl:m', 'pv_measurement']])\n",
    "X_test_estimated_c = X_test_estimated_c.rename(columns={'date_forecast': 'time'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:01:31.791634100Z",
     "start_time": "2023-10-23T21:01:31.745122200Z"
    }
   },
   "id": "44568353acce82ee"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\AppData\\Local\\Temp\\ipykernel_26580\\299797497.py:3: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_matrix = df.corr(method='spearman')\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.95\n",
    "\n",
    "segments = find_long_constant_periods(train_c['pv_measurement'], threshold=5)\n",
    "df = remove_constant_periods(df, segments)\n",
    "\n",
    "df = lag_features_by_one_hour(df, ['diffuse_rad_1h:J', 'direct_rad_1h:J', 'clear_sky_energy_1h:J'])\n",
    "df = is_estimated(df)\n",
    "df = remove_highly_correlated_features(df, threshold)\n",
    "\n",
    "X_test_estimated_c = lag_features_by_one_hour(X_test_estimated_c, ['diffuse_rad_1h:J', 'direct_rad_1h:J', 'clear_sky_energy_1h:J'])\n",
    "X_test_estimated_c = is_estimated(X_test_estimated_c)\n",
    "common_columns = df.columns.intersection(X_test_estimated_c.columns)\n",
    "X_test_estimated_c = X_test_estimated_c.loc[:, common_columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:01:32.616664300Z",
     "start_time": "2023-10-23T21:01:31.807589Z"
    }
   },
   "id": "8ccbc9a77322863e"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "# # Define the split date\n",
    "# split_date = '2022-10-27'\n",
    "# \n",
    "# # Convert the 'time' column to a datetime object\n",
    "# df['time'] = pd.to_datetime(df['time'])\n",
    "# \n",
    "# # Sorting the data by the 'time' column to maintain chronological order\n",
    "# df.sort_values('time', inplace=True)\n",
    "# \n",
    "# # Splitting the data into training and test sets based on the split date\n",
    "# train_df = df[df['time'] < split_date]\n",
    "# test_df = df[df['time'] >= split_date]\n",
    "# \n",
    "# # Identifying the features and the target variable\n",
    "# X_train = train_df.drop(columns=['pv_measurement', 'time'])\n",
    "# y_train = train_df['pv_measurement']\n",
    "# X_test = test_df.drop(columns=['pv_measurement', 'time'])\n",
    "# y_test = test_df['pv_measurement']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:01:32.632664700Z",
     "start_time": "2023-10-23T21:01:32.619663800Z"
    }
   },
   "id": "765271258509f8f3"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "train_end_date = '2022-10-21'\n",
    "# 2023-01-29\n",
    "validation_end_date = '2023-01-29'\n",
    "# 2023-03-16\n",
    "# Convert 'time' column to datetime, if not already\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Split the data into training, validation, and testing sets based on the new split dates\n",
    "train_df = df[df['time'] < train_end_date]\n",
    "validation_df = df[(df['time'] >= train_end_date) & (df['time'] < validation_end_date)]\n",
    "test_df = df[df['time'] >= train_end_date]\n",
    "\n",
    "# Randomly sample data within these periods (assuming you want to keep the same data structure)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "validation_df = validation_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Identifying the features and the target variable\n",
    "X_train = train_df.drop(columns=['pv_measurement', 'time'])\n",
    "y_train = train_df['pv_measurement']\n",
    "X_val = validation_df.drop(columns=['pv_measurement', 'time'])\n",
    "y_val = validation_df['pv_measurement']\n",
    "X_test = test_df.drop(columns=['pv_measurement', 'time'])\n",
    "y_test = test_df['pv_measurement']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:01:32.678222800Z",
     "start_time": "2023-10-23T21:01:32.637667200Z"
    }
   },
   "id": "a974c1c83ddb7df7"
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231023_210132\\\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "WARNING: Attempted to disable saving of bagged fold models when `use_bag_holdout=True`. Forcing `save_bag_folds=True` to avoid errors.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231023_210132\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   953.60 GB / 2047.46 GB (46.6%)\n",
      "Train Data Rows:    29194\n",
      "Train Data Columns: 33\n",
      "Tuning Data Rows:    1304\n",
      "Tuning Data Columns: 33\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 65.22502, 156.16072)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    45844.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.39 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 31 | ['air_density_2m:kgm3', 'ceiling_height_agl:m', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', ...]\n",
      "\t\t('int', [])   :  1 | ['is_estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 29 | ['air_density_2m:kgm3', 'ceiling_height_agl:m', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['is_day:idx', 'is_in_shadow:idx', 'is_estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t32 features in original data used to generate 32 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.87 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.0945\t = Validation score   (-mean_absolute_error)\n",
      "\t34.56s\t = Training   runtime\n",
      "\t24.97s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.16\t = Validation score   (-mean_absolute_error)\n",
      "\t29.7s\t = Training   runtime\n",
      "\t16.74s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-3.9729\t = Validation score   (-mean_absolute_error)\n",
      "\t6.32s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.9411\t = Validation score   (-mean_absolute_error)\n",
      "\t255.59s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-3.9391\t = Validation score   (-mean_absolute_error)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.2577\t = Validation score   (-mean_absolute_error)\n",
      "\t42.92s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.1548\t = Validation score   (-mean_absolute_error)\n",
      "\t95.1s\t = Training   runtime\n",
      "\t19.83s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.0179\t = Validation score   (-mean_absolute_error)\n",
      "\t165.25s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.5919\t = Validation score   (-mean_absolute_error)\n",
      "\t83.73s\t = Training   runtime\n",
      "\t29.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-3.8559\t = Validation score   (-mean_absolute_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.4991\t = Validation score   (-mean_absolute_error)\n",
      "\t4.36s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.5912\t = Validation score   (-mean_absolute_error)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-4.732\t = Validation score   (-mean_absolute_error)\n",
      "\t11.5s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.687\t = Validation score   (-mean_absolute_error)\n",
      "\t23.79s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-4.584\t = Validation score   (-mean_absolute_error)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.6578\t = Validation score   (-mean_absolute_error)\n",
      "\t45.67s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.5066\t = Validation score   (-mean_absolute_error)\n",
      "\t4.03s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.5791\t = Validation score   (-mean_absolute_error)\n",
      "\t117.54s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4.629\t = Validation score   (-mean_absolute_error)\n",
      "\t9.17s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-4.4633\t = Validation score   (-mean_absolute_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1000.81s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t13.75s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t10.83s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL ...\n",
      "\t7.5s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t89.46s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL ...\n",
      "\t1.22s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 27.\n",
      "\t21.96s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t26.9s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t90.08s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t33.76s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.74s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.48s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL ...\n",
      "\t13.97s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t4.84s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL ...\n",
      "\t1.54s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 25.\n",
      "\t19.86s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\t45.35s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t1.67s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.17s\t = Training   runtime\n",
      "Refit complete, total runtime = 395.45s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231023_210132\\\")\n"
     ]
    }
   ],
   "source": [
    "# Combine training and validation data into a single dataset for AutoGluon\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "# Specify the name of the target variable\n",
    "label = 'pv_measurement'\n",
    "\n",
    "# Create a TabularPredictor object\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"mean_absolute_error\").fit(train_data=train_data, tuning_data=val_data, presets='medium_quality', use_bag_holdout=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:24:48.992476Z",
     "start_time": "2023-10-23T21:01:32.696221500Z"
    }
   },
   "id": "cdd55c079d94262b"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                          model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           WeightedEnsemble_L2  -3.855922       1.396158  172.832480                0.000000           0.172312            2       True         10\n",
      "1          ExtraTreesMSE_BAG_L1  -3.939135       0.616113    1.087869                0.616113           1.087869            1       True          5\n",
      "2        RandomForestMSE_BAG_L1  -3.972927       0.536000    6.318659                0.536000           6.318659            1       True          3\n",
      "3         NeuralNetTorch_BAG_L1  -4.017915       0.244045  165.253640                0.244045         165.253640            1       True          8\n",
      "4           WeightedEnsemble_L3  -4.463264      93.827456  886.017106                0.000000           0.167528            3       True         20\n",
      "5             LightGBMXT_BAG_L2  -4.499108      92.974852  718.622205                0.224792           4.357846            2       True         11\n",
      "6                XGBoost_BAG_L2  -4.506587      92.865635  718.290156                0.115576           4.025798            2       True         17\n",
      "7         NeuralNetTorch_BAG_L2  -4.579063      93.126881  831.800034                0.376822         117.535675            2       True         18\n",
      "8          ExtraTreesMSE_BAG_L2  -4.583965      93.328790  715.657753                0.578731           1.393395            2       True         15\n",
      "9               LightGBM_BAG_L2  -4.591202      92.850062  716.609695                0.100003           2.345337            2       True         12\n",
      "10         LightGBMLarge_BAG_L1  -4.591925      29.294616   83.729419               29.294616          83.729419            1       True          9\n",
      "11         LightGBMLarge_BAG_L2  -4.629046      92.998114  723.430855                0.248055           9.166497            2       True         19\n",
      "12       NeuralNetFastAI_BAG_L2  -4.657830      93.110266  759.930258                0.360206          45.665900            2       True         16\n",
      "13              CatBoost_BAG_L2  -4.687049      92.808698  738.056417                0.058638          23.792058            2       True         14\n",
      "14       RandomForestMSE_BAG_L2  -4.731958      93.346815  725.765433                0.596755          11.501074            2       True         13\n",
      "15            LightGBMXT_BAG_L1  -5.094468      24.966932   34.564530               24.966932          34.564530            1       True          1\n",
      "16               XGBoost_BAG_L1  -5.154767      19.833659   95.098984               19.833659          95.098984            1       True          7\n",
      "17              LightGBM_BAG_L1  -5.159982      16.738278   29.703791               16.738278          29.703791            1       True          2\n",
      "18       NeuralNetFastAI_BAG_L1  -5.257661       0.367401   42.918966                0.367401          42.918966            1       True          6\n",
      "19              CatBoost_BAG_L1  -5.941118       0.153016  255.588500                0.153016         255.588500            1       True          4\n",
      "20          XGBoost_BAG_L2_FULL        NaN            NaN  295.758827                     NaN           0.317165            2       True         37\n",
      "21          XGBoost_BAG_L1_FULL        NaN            NaN   26.897182                     NaN          26.897182            1       True         27\n",
      "22     WeightedEnsemble_L3_FULL        NaN            NaN  361.870443                     NaN           0.167528            3       True         40\n",
      "23     WeightedEnsemble_L2_FULL        NaN            NaN   98.970254                     NaN           0.172312            2       True         30\n",
      "24  RandomForestMSE_BAG_L2_FULL        NaN            NaN  309.413006                     NaN          13.971344            2       True         33\n",
      "25  RandomForestMSE_BAG_L1_FULL        NaN            NaN    7.498988                     NaN           7.498988            1       True         23\n",
      "26   NeuralNetTorch_BAG_L2_FULL        NaN            NaN  340.787763                     NaN          45.346101            2       True         38\n",
      "27   NeuralNetTorch_BAG_L1_FULL        NaN            NaN   90.082473                     NaN          90.082473            1       True         28\n",
      "28  NeuralNetFastAI_BAG_L2_FULL        NaN            NaN  315.302882                     NaN          19.861220            2       True         36\n",
      "29  NeuralNetFastAI_BAG_L1_FULL        NaN            NaN   21.955693                     NaN          21.955693            1       True         26\n",
      "30         LightGBM_BAG_L2_FULL        NaN            NaN  295.924649                     NaN           0.482986            2       True         32\n",
      "31         LightGBM_BAG_L1_FULL        NaN            NaN   10.827932                     NaN          10.827932            1       True         22\n",
      "32       LightGBMXT_BAG_L2_FULL        NaN            NaN  296.178429                     NaN           0.736767            2       True         31\n",
      "33       LightGBMXT_BAG_L1_FULL        NaN            NaN   13.752255                     NaN          13.752255            1       True         21\n",
      "34    LightGBMLarge_BAG_L2_FULL        NaN            NaN  297.108786                     NaN           1.667123            2       True         39\n",
      "35    LightGBMLarge_BAG_L1_FULL        NaN            NaN   33.755068                     NaN          33.755068            1       True         29\n",
      "36    ExtraTreesMSE_BAG_L2_FULL        NaN            NaN  296.980947                     NaN           1.539284            2       True         35\n",
      "37    ExtraTreesMSE_BAG_L1_FULL        NaN            NaN    1.216480                     NaN           1.216480            1       True         25\n",
      "38         CatBoost_BAG_L2_FULL        NaN            NaN  300.282409                     NaN           4.840747            2       True         34\n",
      "39         CatBoost_BAG_L1_FULL        NaN            NaN   89.455590                     NaN          89.455590            1       True         24\n",
      "Number of models trained: 40\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 29 | ['air_density_2m:kgm3', 'ceiling_height_agl:m', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', ...]\n",
      "('int', ['bool']) :  3 | ['is_day:idx', 'is_in_shadow:idx', 'is_estimated']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\Desktop\\Envs\\MLenv\\lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:24:49.087302900Z",
     "start_time": "2023-10-23T21:24:48.997592Z"
    }
   },
   "id": "dbf9458b87fc5239"
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(X_test_estimated_c)\n",
    "y_pred = y_pred.clip(lower=0)\n",
    "y_pred = y_pred.reset_index(drop=True)\n",
    "y_pred.index.name = 'id'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:24:49.475867600Z",
     "start_time": "2023-10-23T21:24:49.089300300Z"
    }
   },
   "id": "d9482667a02af855"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
    "df.to_csv('result_c.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T21:24:49.491729600Z",
     "start_time": "2023-10-23T21:24:49.478873800Z"
    }
   },
   "id": "7c9c0cb5ad7af0a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
