{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import xgboost as xgb\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T13:17:57.067608500Z",
     "start_time": "2023-10-01T13:17:56.904177Z"
    }
   },
   "id": "606d191f30ff102a"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Feature  XGB_Importance  pv_measurement  Mutual_Info  \\\n",
      "10           direct_rad:W        0.560381        0.853315     0.737941   \n",
      "4         clear_sky_rad:W        0.042977        0.803990     0.845601   \n",
      "36        sun_elevation:d        0.013142        0.691070     0.914885   \n",
      "8           diffuse_rad:W        0.058068        0.705704     0.802399   \n",
      "3   clear_sky_energy_1h:J        0.004355        0.781647     0.739144   \n",
      "11        direct_rad_1h:J        0.005773        0.828454     0.673928   \n",
      "9        diffuse_rad_1h:J        0.005839        0.689930     0.699093   \n",
      "19             is_day:idx        0.000000        0.537770     0.565029   \n",
      "35          sun_azimuth:d        0.039064       -0.064520     0.622470   \n",
      "38            t_1000hPa:K        0.012213        0.338399     0.088628   \n",
      "\n",
      "    Total_Importance  \n",
      "10          2.151636  \n",
      "4           1.692568  \n",
      "36          1.619097  \n",
      "8           1.566170  \n",
      "3           1.525147  \n",
      "11          1.508155  \n",
      "9           1.394862  \n",
      "19          1.102798  \n",
      "35          0.597015  \n",
      "38          0.439240  \n"
     ]
    }
   ],
   "source": [
    "# Load your data (replace these lines with your actual data loading code)\n",
    "X_train_observed = pd.read_csv(\"X_train_observed.csv\")\n",
    "train_targets = pd.read_csv(\"train_targets.csv\")\n",
    "\n",
    "# Align your data based on timestamps (if needed)\n",
    "aligned_data = pd.merge(train_targets, X_train_observed, left_on='time', right_on='date_forecast', how='inner')\n",
    "y_aligned = aligned_data['pv_measurement']\n",
    "X_aligned = aligned_data.drop(['time', 'pv_measurement', 'date_forecast'], axis=1)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "# Time-based Splitting (replace 'time' and 'date_forecast' with your actual timestamp columns)\n",
    "aligned_data = aligned_data.sort_values(by='time')  # Sorting by time\n",
    "train_size = int(len(aligned_data) * 0.8)  # Using 80% for training\n",
    "\n",
    "# Split the aligned data into training and validation sets based on time\n",
    "train_data = aligned_data[:train_size]\n",
    "val_data = aligned_data[train_size:]\n",
    "\n",
    "# Separate features and target variable for both training and validation sets\n",
    "X_train = train_data.drop(['time', 'pv_measurement', 'date_forecast'], axis=1)\n",
    "y_train = train_data['pv_measurement']\n",
    "X_val = val_data.drop(['time', 'pv_measurement', 'date_forecast'], axis=1)\n",
    "y_val = val_data['pv_measurement']\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "xgb_model = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_feature_importance = xgb_model.feature_importances_\n",
    "xgb_feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'XGB_Importance': xgb_feature_importance})\n",
    "\n",
    "# Pearson's Correlation (Excluding the timestamp column)\n",
    "correlation_matrix = aligned_data.drop(['time', 'date_forecast'], axis=1).corr()\n",
    "correlation_with_target = correlation_matrix['pv_measurement'].sort_values(ascending=False)\n",
    "\n",
    "# Mutual Information\n",
    "mutual_info = mutual_info_regression(X_train, y_train)\n",
    "mutual_info_df = pd.DataFrame({'Feature': X_train.columns, 'Mutual_Info': mutual_info})\n",
    "\n",
    "# Combine All Feature Importances\n",
    "combined_feature_importance_df = pd.merge(pd.merge(xgb_feature_importance_df, correlation_with_target, left_on='Feature', right_index=True), mutual_info_df, on='Feature')\n",
    "combined_feature_importance_df['Total_Importance'] = combined_feature_importance_df['XGB_Importance'] + combined_feature_importance_df['pv_measurement'] + combined_feature_importance_df['Mutual_Info']\n",
    "\n",
    "# Sort by Total Importance\n",
    "sorted_combined_feature_importance_df = combined_feature_importance_df.sort_values(by='Total_Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 most consistently important features\n",
    "top_10_combined_features = sorted_combined_feature_importance_df.head(10)\n",
    "print(top_10_combined_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T13:18:03.798136500Z",
     "start_time": "2023-10-01T13:17:57.196903500Z"
    }
   },
   "id": "ba15770cf620e015"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4e128bdc9abf77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
