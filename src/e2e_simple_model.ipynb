{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_calc</th>\n",
       "      <th>date_forecast</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>...</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-27 07:00:18</td>\n",
       "      <td>2022-10-28 22:00:00</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.233</td>\n",
       "      <td>1425.099976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1211.699951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.399994</td>\n",
       "      <td>...</td>\n",
       "      <td>340.799011</td>\n",
       "      <td>-38.466999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.700012</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>29429.699219</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-27 07:00:18</td>\n",
       "      <td>2022-10-28 22:15:00</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.233</td>\n",
       "      <td>2085.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1560.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>345.451996</td>\n",
       "      <td>-38.955002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.700012</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>23604.099609</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-27 07:00:18</td>\n",
       "      <td>2022-10-28 22:30:00</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.233</td>\n",
       "      <td>2746.600098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1909.400024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>350.153015</td>\n",
       "      <td>-39.310001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.700012</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17799.800781</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-27 07:00:18</td>\n",
       "      <td>2022-10-28 22:45:00</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.233</td>\n",
       "      <td>3407.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2258.199951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>354.886993</td>\n",
       "      <td>-39.528999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.600006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12016.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-27 07:00:18</td>\n",
       "      <td>2022-10-28 23:00:00</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.233</td>\n",
       "      <td>4068.199951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2607.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.100006</td>\n",
       "      <td>...</td>\n",
       "      <td>359.638000</td>\n",
       "      <td>-39.609001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.600006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6254.399902</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17571</th>\n",
       "      <td>2023-04-29 07:00:05</td>\n",
       "      <td>2023-04-30 22:45:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.281</td>\n",
       "      <td>1173.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>536.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>352.920013</td>\n",
       "      <td>-11.731000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>11629.299805</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17572</th>\n",
       "      <td>2023-04-29 07:00:05</td>\n",
       "      <td>2023-04-30 23:00:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.281</td>\n",
       "      <td>1054.199951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>542.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>356.634003</td>\n",
       "      <td>-11.884000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9923.200195</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17573</th>\n",
       "      <td>2023-04-29 07:00:05</td>\n",
       "      <td>2023-04-30 23:15:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.281</td>\n",
       "      <td>1435.800049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.799988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>-11.928000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>11230.799805</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17574</th>\n",
       "      <td>2023-04-29 07:00:05</td>\n",
       "      <td>2023-04-30 23:30:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.281</td>\n",
       "      <td>1817.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>521.200012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>-11.864000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>99.599998</td>\n",
       "      <td>12526.099609</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17575</th>\n",
       "      <td>2023-04-29 07:00:05</td>\n",
       "      <td>2023-04-30 23:45:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2198.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.700012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>7.782000</td>\n",
       "      <td>-11.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.299988</td>\n",
       "      <td>99.300003</td>\n",
       "      <td>13809.099609</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17576 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_calc       date_forecast  absolute_humidity_2m:gm3  \\\n",
       "0     2022-10-27 07:00:18 2022-10-28 22:00:00                       8.4   \n",
       "1     2022-10-27 07:00:18 2022-10-28 22:15:00                       8.4   \n",
       "2     2022-10-27 07:00:18 2022-10-28 22:30:00                       8.3   \n",
       "3     2022-10-27 07:00:18 2022-10-28 22:45:00                       8.3   \n",
       "4     2022-10-27 07:00:18 2022-10-28 23:00:00                       8.2   \n",
       "...                   ...                 ...                       ...   \n",
       "17571 2023-04-29 07:00:05 2023-04-30 22:45:00                       4.5   \n",
       "17572 2023-04-29 07:00:05 2023-04-30 23:00:00                       4.5   \n",
       "17573 2023-04-29 07:00:05 2023-04-30 23:15:00                       4.5   \n",
       "17574 2023-04-29 07:00:05 2023-04-30 23:30:00                       4.5   \n",
       "17575 2023-04-29 07:00:05 2023-04-30 23:45:00                       4.5   \n",
       "\n",
       "       air_density_2m:kgm3  ceiling_height_agl:m  clear_sky_energy_1h:J  \\\n",
       "0                    1.233           1425.099976                    0.0   \n",
       "1                    1.233           2085.899902                    0.0   \n",
       "2                    1.233           2746.600098                    0.0   \n",
       "3                    1.233           3407.399902                    0.0   \n",
       "4                    1.233           4068.199951                    0.0   \n",
       "...                    ...                   ...                    ...   \n",
       "17571                1.281           1173.900024                    0.0   \n",
       "17572                1.281           1054.199951                    0.0   \n",
       "17573                1.281           1435.800049                    0.0   \n",
       "17574                1.281           1817.400024                    0.0   \n",
       "17575                1.281           2198.899902                    0.0   \n",
       "\n",
       "       clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0                  0.0       1211.699951              1.0      281.399994   \n",
       "1                  0.0       1560.500000              1.0      281.299988   \n",
       "2                  0.0       1909.400024              1.0      281.200012   \n",
       "3                  0.0       2258.199951              1.0      281.200012   \n",
       "4                  0.0       2607.000000              1.0      281.100006   \n",
       "...                ...               ...              ...             ...   \n",
       "17571              0.0        536.500000              0.0      272.299988   \n",
       "17572              0.0        542.400024              0.0      272.200012   \n",
       "17573              0.0        531.799988              0.0      272.299988   \n",
       "17574              0.0        521.200012              0.0      272.299988   \n",
       "17575              0.0        510.700012              0.0      272.299988   \n",
       "\n",
       "       ...  sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "0      ...     340.799011       -38.466999                             0.0   \n",
       "1      ...     345.451996       -38.955002                             0.0   \n",
       "2      ...     350.153015       -39.310001                             0.0   \n",
       "3      ...     354.886993       -39.528999                             0.0   \n",
       "4      ...     359.638000       -39.609001                             0.0   \n",
       "...    ...            ...              ...                             ...   \n",
       "17571  ...     352.920013       -11.731000                             0.1   \n",
       "17572  ...     356.634003       -11.884000                             0.1   \n",
       "17573  ...       0.352000       -11.928000                             0.1   \n",
       "17574  ...       4.070000       -11.864000                             0.1   \n",
       "17575  ...       7.782000       -11.690000                             0.0   \n",
       "\n",
       "       t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0       284.700012           100.000000  29429.699219                0.8   \n",
       "1       284.700012           100.000000  23604.099609                0.7   \n",
       "2       284.700012           100.000000  17799.800781                0.7   \n",
       "3       284.600006           100.000000  12016.500000                0.6   \n",
       "4       284.600006           100.000000   6254.399902                0.6   \n",
       "...            ...                  ...           ...                ...   \n",
       "17571   274.200012            99.900002  11629.299805                3.9   \n",
       "17572   274.200012           100.000000   9923.200195                3.7   \n",
       "17573   274.200012            99.900002  11230.799805                3.7   \n",
       "17574   274.200012            99.599998  12526.099609                3.8   \n",
       "17575   274.299988            99.300003  13809.099609                3.8   \n",
       "\n",
       "       wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \n",
       "0                     -0.4                  0.7                     -0.0  \n",
       "1                     -0.4                  0.7                     -0.0  \n",
       "2                     -0.3                  0.6                     -0.0  \n",
       "3                     -0.2                  0.6                     -0.0  \n",
       "4                     -0.1                  0.6                     -0.0  \n",
       "...                    ...                  ...                      ...  \n",
       "17571                  2.9                  2.5                     -0.0  \n",
       "17572                  2.8                  2.4                     -0.0  \n",
       "17573                  2.7                  2.5                     -0.0  \n",
       "17574                  2.7                  2.6                     -0.0  \n",
       "17575                  2.7                  2.7                     -0.0  \n",
       "\n",
       "[17576 rows x 47 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_train_targets = pd.read_parquet('./data/A/train_targets.parquet')\n",
    "A_X_train_estimated = pd.read_parquet('./data/A/X_train_estimated.parquet')\n",
    "A_X_train_observed = pd.read_parquet('./data/A/X_train_observed.parquet')\n",
    "A_X_test = pd.read_parquet('./data/A/X_test_estimated.parquet')\n",
    "\n",
    "B_train_targets = pd.read_parquet('./data/B/train_targets.parquet')\n",
    "B_X_train_estimated = pd.read_parquet('./data/B/X_train_estimated.parquet')\n",
    "B_X_train_observed = pd.read_parquet('./data/B/X_train_observed.parquet')\n",
    "B_X_test = pd.read_parquet('./data/B/X_test_estimated.parquet')\n",
    "\n",
    "C_train_targets = pd.read_parquet('./data/B/train_targets.parquet')\n",
    "C_X_train_estimated = pd.read_parquet('./data/B/X_train_estimated.parquet')\n",
    "C_X_train_observed = pd.read_parquet('./data/B/X_train_observed.parquet')\n",
    "C_X_test = pd.read_parquet('./data/B/X_test_estimated.parquet')\n",
    "\n",
    "X_train_estimated = {\n",
    "    'A': A_X_train_estimated,\n",
    "    'B': B_X_train_estimated,\n",
    "    'C': C_X_train_estimated,\n",
    "}\n",
    "X_train_observed = {\n",
    "    'A': A_X_train_observed,\n",
    "    'B': B_X_train_observed,\n",
    "    'C': C_X_train_observed,\n",
    "}\n",
    "train_targets = {\n",
    "    'A': A_train_targets,\n",
    "    'B': B_train_targets,\n",
    "    'C': C_train_targets,\n",
    "}\n",
    "X_test_submission = {\n",
    "    'A': A_X_test,\n",
    "    'B': B_X_test,\n",
    "    'C': C_X_test,\n",
    "}\n",
    "\n",
    "X_train_estimated['A']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "result is a single dictionary `train_set_merged` with the keys `A`, `B` and `C`, for each corresponding location. one new feature is added: `location`, and the prediction-target is added as a columns as well: `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Categorical' with dtype category does not support reduction 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/torstein/school-projects/maskinlæring/MLGroupProject/src/e2e_simple_model.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m merged[[\u001b[39m'\u001b[39m\u001b[39mceiling_height_agl:m\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcloud_base_agl:m\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m imputer\u001b[39m.\u001b[39mfit_transform(merged[[\u001b[39m'\u001b[39m\u001b[39mceiling_height_agl:m\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcloud_base_agl:m\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Filling rows with NaN values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Define the default fill value\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m merged \u001b[39m=\u001b[39m merged\u001b[39m.\u001b[39mfillna(merged\u001b[39m.\u001b[39;49mtransform(\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m train_set_merged[location] \u001b[39m=\u001b[39m merged\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/frame.py:9863\u001b[0m, in \u001b[0;36mDataFrame.transform\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   9860\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9862\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\u001b[39mself\u001b[39m, func\u001b[39m=\u001b[39mfunc, axis\u001b[39m=\u001b[39maxis, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m-> 9863\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49mtransform()\n\u001b[1;32m   9864\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(result, DataFrame)\n\u001b[1;32m   9865\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/apply.py:231\u001b[0m, in \u001b[0;36mApply.transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m func \u001b[39m=\u001b[39m cast(AggFuncTypeBase, func)\n\u001b[1;32m    230\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_str_or_callable(func)\n\u001b[1;32m    232\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/apply.py:289\u001b[0m, in \u001b[0;36mApply.transform_str_or_callable\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    286\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_str(obj, func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs:\n\u001b[1;32m    292\u001b[0m     f \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/apply.py:669\u001b[0m, in \u001b[0;36mApply._apply_str\u001b[0;34m(self, obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, func)\n\u001b[1;32m    668\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(f):\n\u001b[0;32m--> 669\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    671\u001b[0m \u001b[39m# people may aggregate on a non-callable attribute\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[39m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/frame.py:11338\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11330\u001b[0m \u001b[39m@doc\u001b[39m(make_doc(\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m  11331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11332\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11336\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11337\u001b[0m ):\n\u001b[0;32m> 11338\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mmean(axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m  11339\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Series):\n\u001b[1;32m  11340\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/generic.py:11978\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11971\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11972\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11973\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11976\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11977\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11979\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11980\u001b[0m     )\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/generic.py:11935\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11931\u001b[0m nv\u001b[39m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  11933\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m> 11935\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11936\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11937\u001b[0m )\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/frame.py:11207\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11203\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mT\n\u001b[1;32m  11205\u001b[0m \u001b[39m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  11206\u001b[0m \u001b[39m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 11207\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreduce(blk_func)\n\u001b[1;32m  11208\u001b[0m out \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_constructor_from_mgr(res, axes\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[1;32m  11209\u001b[0m \u001b[39mif\u001b[39;00m out_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m out\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1457\u001b[0m res_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[1;32m   1458\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m-> 1459\u001b[0m     nbs \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mreduce(func)\n\u001b[1;32m   1460\u001b[0m     res_blocks\u001b[39m.\u001b[39mextend(nbs)\n\u001b[1;32m   1462\u001b[0m index \u001b[39m=\u001b[39m Index([\u001b[39mNone\u001b[39;00m])  \u001b[39m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce\u001b[39m(\u001b[39mself\u001b[39m, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[1;32m    373\u001b[0m     \u001b[39m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[39m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m--> 377\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues)\n\u001b[1;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    380\u001b[0m         res_values \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/frame.py:11128\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  11126\u001b[0m     dtype_has_keepdims[values\u001b[39m.\u001b[39mdtype] \u001b[39m=\u001b[39m has_keepdims\n\u001b[1;32m  11127\u001b[0m \u001b[39mif\u001b[39;00m has_keepdims:\n\u001b[0;32m> 11128\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39;49m_reduce(name, skipna\u001b[39m=\u001b[39;49mskipna, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m  11129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m  11130\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m  11131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(values)\u001b[39m}\u001b[39;00m\u001b[39m._reduce will require a `keepdims` parameter \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  11132\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min the future\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m  11133\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m  11134\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11135\u001b[0m     )\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:2325\u001b[0m, in \u001b[0;36mCategorical._reduce\u001b[0;34m(self, name, skipna, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_reduce\u001b[39m(\n\u001b[1;32m   2323\u001b[0m     \u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m, skipna: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, keepdims: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m   2324\u001b[0m ):\n\u001b[0;32m-> 2325\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_reduce(name, skipna\u001b[39m=\u001b[39;49mskipna, keepdims\u001b[39m=\u001b[39;49mkeepdims, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2326\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39margmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39margmin\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   2327\u001b[0m         \u001b[39m# don't wrap in Categorical!\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/pandas/core/arrays/base.py:1857\u001b[0m, in \u001b[0;36mExtensionArray._reduce\u001b[0;34m(self, name, skipna, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   1855\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, name, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1856\u001b[0m \u001b[39mif\u001b[39;00m meth \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1858\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with dtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1859\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdoes not support reduction \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1860\u001b[0m     )\n\u001b[1;32m   1861\u001b[0m result \u001b[39m=\u001b[39m meth(skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1862\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Categorical' with dtype category does not support reduction 'mean'"
     ]
    }
   ],
   "source": [
    "# Marking each row with its location origin\n",
    "for location in X_train_estimated.keys():\n",
    "    X_train_estimated[location]['location'] = location\n",
    "    X_train_observed[location]['location'] = location\n",
    "    X_test_submission[location]['location'] = location\n",
    "    X_train_estimated[location]['location'] = X_train_estimated[location]['location'].astype('category')\n",
    "    X_train_observed[location]['location'] = X_train_observed[location]['location'].astype('category')\n",
    "    X_test_submission[location]['location'] = X_test_submission[location]['location'].astype('category')\n",
    "\n",
    "# Making a test set for each location\n",
    "train_set_merged = {}\n",
    "for location in X_train_estimated.keys():\n",
    "    # concatinating observed and estimated\n",
    "    concatinated = pd.concat(\n",
    "        [X_train_observed[location], X_train_estimated[location]]\n",
    "    )\n",
    "    \n",
    "    # merging target value into the training set\n",
    "    merged = pd.merge(\n",
    "        concatinated,\n",
    "        train_targets[location],\n",
    "        left_on='date_forecast',\n",
    "        right_on='time',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # dropping dates\n",
    "    merged = merged.drop(columns=['date_calc', 'date_forecast'])\n",
    "\n",
    "    # dropping some other shit\n",
    "    merged = merged.drop(columns=['elevation:m', 'snow_density:kgm3', 'snow_drift:idx'], axis=1)\n",
    "\n",
    "    # filling bad samples\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    merged[['ceiling_height_agl:m', 'cloud_base_agl:m']] = imputer.fit_transform(merged[['ceiling_height_agl:m', 'cloud_base_agl:m']])\n",
    "\n",
    "    # Filling rows with NaN values\n",
    "    # Define the default fill value\n",
    "    merged = merged.fillna(merged.transform('mean'))\n",
    "\n",
    "\n",
    "    train_set_merged[location] = merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into test-set and train-set\n",
    "Both having seperate prediction-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = '2022-10-27'\n",
    "# split_date = '2023-04-20'\n",
    "\n",
    "X_train_dict = {}\n",
    "y_train_dict = {}\n",
    "X_test_dict = {}\n",
    "y_test_dict = {}\n",
    "\n",
    "for location in train_set_merged.keys():\n",
    "    set = train_set_merged[location]\n",
    "    set['time'] = pd.to_datetime(train_set_merged[location]['time'])\n",
    "    set.sort_values('time', inplace=True)\n",
    "\n",
    "    train_set = set[set['time'] < split_date]\n",
    "    test_set = set[set['time'] >= split_date]\n",
    "\n",
    "    X_train = train_set.drop(columns=['pv_measurement'])\n",
    "    y_train = train_set['pv_measurement']\n",
    "    X_test = test_set.drop(columns=['pv_measurement'])\n",
    "    y_test = test_set['pv_measurement']\n",
    "\n",
    "    X_train_dict[location] = X_train\n",
    "    y_train_dict[location] = y_train\n",
    "    X_test_dict[location] = X_test\n",
    "    y_test_dict[location] = y_test\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### truncate data to one set regardless of location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concatinated = pd.concat(X_train_dict.values())\n",
    "y_train_concatinated = pd.concat(y_train_dict.values())\n",
    "X_train_concatinated['location'] = X_train_concatinated['location'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temporary: drop categorical location. it does not work how it is supposed to\n",
    "\n",
    "# X_train_concatinated = X_train_concatinated.drop(columns=['location'])\n",
    "\n",
    "# for location in X_test_dict.keys():\n",
    "#     X_train_dict[location] = X_train_dict[location].drop(columns=['location'])\n",
    "#     X_test_dict[location] = X_test_dict[location].drop(columns=['location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy without time\n",
    "X_train_concatinated_timeless = X_train_concatinated.drop(columns=['time'])\n",
    "\n",
    "X_train_timeless = X_train_dict.copy()\n",
    "X_test_timeless = X_test_dict.copy()\n",
    "for location in X_test_dict.keys():\n",
    "    X_train_timeless[location] = X_train_dict[location].drop(columns=['time'])\n",
    "    X_test_timeless[location] = X_test_dict[location].drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:463: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  or is_sparse(dtype)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:464: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  or (is_categorical_dtype(dtype) and enable_categorical)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:401: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(ser.dtype):\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[16:29:50] /workspace/src/data/data.cc:507: Check failed: valid: Label contains NaN, infinity or a value too large.\nStack trace:\n  [bt] (0) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x3581ea) [0x7f12471581ea]\n  [bt] (1) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x389b7d) [0x7f1247189b7d]\n  [bt] (2) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x38a4b1) [0x7f124718a4b1]\n  [bt] (3) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xb0) [0x7f1246f5e210]\n  [bt] (4) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7f12d4e2fe2e]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7f12d4e2c493]\n  [bt] (6) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7f12d4ae93e9]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x7f12d4ae8a00]\n  [bt] (8) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/bin/python(_PyObject_MakeTpCall+0x25b) [0x562f118b95eb]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/torstein/school-projects/maskinlæring/MLGroupProject/src/e2e_simple_model.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xgb_model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(enable_categorical\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m xgb_model\u001b[39m.\u001b[39;49mfit(X_train_concatinated_timeless, y_train_concatinated)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/torstein/school-projects/maskinl%C3%A6ring/MLGroupProject/src/e2e_simple_model.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgb_model\u001b[39m.\u001b[39mpredict(X_test_timeless[\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1051\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[1;32m   1050\u001b[0m     evals_result: TrainingCallback\u001b[39m.\u001b[39mEvalsLog \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1051\u001b[0m     train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1052\u001b[0m         missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1053\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1054\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1055\u001b[0m         group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1056\u001b[0m         qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1057\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1058\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1059\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1060\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1061\u001b[0m         sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1062\u001b[0m         base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1063\u001b[0m         eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1064\u001b[0m         eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1065\u001b[0m         create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1066\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1067\u001b[0m         feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1068\u001b[0m     )\n\u001b[1;32m   1069\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1071\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/sklearn.py:534\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    515\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    516\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    531\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    532\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    535\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    536\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    537\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    538\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    539\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    540\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    541\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    542\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    543\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    544\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    545\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    546\u001b[0m     )\n\u001b[1;32m    548\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    550\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/sklearn.py:954\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m _can_use_qdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_method) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbooster \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    953\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m         \u001b[39mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[1;32m    955\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, ref\u001b[39m=\u001b[39;49mref, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, max_bin\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_bin\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    957\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:1528\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1509\u001b[0m         info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m         \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         )\n\u001b[1;32m   1522\u001b[0m     ):\n\u001b[1;32m   1523\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1524\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf data iterator is used as input, data like label should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1525\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mspecified as batch argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1526\u001b[0m         )\n\u001b[0;32m-> 1528\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(\n\u001b[1;32m   1529\u001b[0m     data,\n\u001b[1;32m   1530\u001b[0m     ref\u001b[39m=\u001b[39;49mref,\n\u001b[1;32m   1531\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   1532\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m   1533\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1534\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   1535\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m   1536\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[1;32m   1537\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[1;32m   1538\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1539\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m   1540\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m   1541\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m   1542\u001b[0m )\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:1587\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1575\u001b[0m config \u001b[39m=\u001b[39m make_jcargs(\n\u001b[1;32m   1576\u001b[0m     nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnthread, missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing, max_bin\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_bin\n\u001b[1;32m   1577\u001b[0m )\n\u001b[1;32m   1578\u001b[0m ret \u001b[39m=\u001b[39m _LIB\u001b[39m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[1;32m   1579\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1580\u001b[0m     it\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     ctypes\u001b[39m.\u001b[39mbyref(handle),\n\u001b[1;32m   1586\u001b[0m )\n\u001b[0;32m-> 1587\u001b[0m it\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1588\u001b[0m \u001b[39m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m _check_call(ret)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:556\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m dft_ret\n\u001b[1;32m    555\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[1;32m    557\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[39m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[39m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[39m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:640\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_ref \u001b[39m=\u001b[39m ref\n\u001b[1;32m    639\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_exception(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(input_data), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:1260\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1260\u001b[0m input_data(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:632\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data \u001b[39m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n\u001b[1;32m    631\u001b[0m dispatch_proxy_set_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy, new, cat_codes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_host)\n\u001b[0;32m--> 632\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproxy\u001b[39m.\u001b[39;49mset_info(\n\u001b[1;32m    633\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m    634\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    635\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    636\u001b[0m )\n\u001b[1;32m    637\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_ref \u001b[39m=\u001b[39m ref\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:931\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[0;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m    930\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_label(label)\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_weight(weight)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:1069\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \n\u001b[1;32m   1062\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[39m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m-> 1069\u001b[0m dispatch_meta_backend(\u001b[39mself\u001b[39;49m, label, \u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:1205\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[0;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_series(data):\n\u001b[0;32m-> 1205\u001b[0m     _meta_from_pandas_series(data, name, dtype, handle)\n\u001b[1;32m   1206\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[39mif\u001b[39;00m _is_dlpack(data):\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:523\u001b[0m, in \u001b[0;36m_meta_from_pandas_series\u001b[0;34m(data, name, dtype, handle)\u001b[0m\n\u001b[1;32m    521\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto_dense()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 523\u001b[0m _meta_from_numpy(data, name, dtype, handle)\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:1139\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[0;34m(data, field, dtype, handle)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMasked array is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1138\u001b[0m interface_str \u001b[39m=\u001b[39m _array_interface(data)\n\u001b[0;32m-> 1139\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "File \u001b[0;32m~/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/core.py:281\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[1;32m    272\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [16:29:50] /workspace/src/data/data.cc:507: Check failed: valid: Label contains NaN, infinity or a value too large.\nStack trace:\n  [bt] (0) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x3581ea) [0x7f12471581ea]\n  [bt] (1) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x389b7d) [0x7f1247189b7d]\n  [bt] (2) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x38a4b1) [0x7f124718a4b1]\n  [bt] (3) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xb0) [0x7f1246f5e210]\n  [bt] (4) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7f12d4e2fe2e]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7f12d4e2c493]\n  [bt] (6) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7f12d4ae93e9]\n  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x7f12d4ae8a00]\n  [bt] (8) /home/torstein/school-projects/maskinlæring/MLGroupProject/venv/bin/python(_PyObject_MakeTpCall+0x25b) [0x562f118b95eb]\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_model = xgb.XGBRegressor(enable_categorical=True)\n",
    "xgb_model.fit(X_train_concatinated_timeless, y_train_concatinated)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test_timeless['A'])\n",
    "y_pred = np.maximum(y_pred, 0)\n",
    "# Calculate MAE on the test set\n",
    "mae = mean_absolute_error(y_test_dict['A'], y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use trained model to generate submisstion file\n",
    "submission file: `data/sample_submission.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make predictions for A, B and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['date_forecast', 'date_calc', 'elevation:m', 'snow_density:kgm3', 'snow_drift:idx']\n",
    "\n",
    "X_test_submission_concatinated = pd.concat(X_test_submission.values())\n",
    "X_test_submission_concatinated['location'] = X_test_submission_concatinated['location'].astype('category')\n",
    "# X_test_submission_concatinated_pred = X_test_submission_concatinated.copy()\n",
    "# X_test_submission_concatinated_pred['prediction'] = xgb_model.predict(X_test_submission_concatinated.drop(columns=columns_to_drop))\n",
    "\n",
    "# X_test_submission_pred = X_test_submission.copy()\n",
    "# for location in X_test_submission.keys():\n",
    "#     X_test_submission_pred[location]['prediction'] = xgb_model.predict(X_test_submission[location].drop(columns=columns_to_drop))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load test.csv and write to sample_submission.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = \"data/test.csv\"\n",
    "# sample_submission_file = \"data/sample_submission_test.csv\"\n",
    "\n",
    "# test_csv = pd.read_csv(csv_file)\n",
    "# test_csv['time'] = pd.to_datetime(test_csv['time'])\n",
    "# X_test_submission_concatinated_pred\n",
    "\n",
    "# sample_submission = pd.merge(test_csv, X_test_submission_concatinated_pred, left_on=['time', 'location'], right_on=['date_forecast', 'location'], how='inner')\n",
    "# sample_submission = sample_submission[['id', 'prediction_y']]\n",
    "# sample_submission = sample_submission.rename(columns={'prediction_y': 'prediction'})\n",
    "# sample_submission.to_csv(sample_submission_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for generating predictions-csv for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:463: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  or is_sparse(dtype)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:464: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  or (is_categorical_dtype(dtype) and enable_categorical)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/torstein/school-projects/maskinlæring/MLGroupProject/venv/lib/python3.10/site-packages/xgboost/data.py:401: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(ser.dtype):\n"
     ]
    }
   ],
   "source": [
    "def gen_pred_csv_from_trained_model(model, X_test, test_csv_path, sample_submission_csv_path, columns_to_drop):\n",
    "    predictions = model.predict(X_test.drop(columns=columns_to_drop))\n",
    "    X_test_with_prediction = X_test.copy()\n",
    "    X_test_with_prediction['prediction'] = predictions\n",
    "\n",
    "    X_test_with_prediction\n",
    "\n",
    "    test_csv = pd.read_csv(test_csv_path)\n",
    "    test_csv['time'] = pd.to_datetime(test_csv['time'])\n",
    "\n",
    "    sample_submission = pd.merge(test_csv, X_test_with_prediction, left_on=['time', 'location'], right_on=['date_forecast', 'location'], how='inner')\n",
    "    sample_submission = sample_submission[['id', 'prediction_y']]\n",
    "    sample_submission = sample_submission.rename(columns={'prediction_y': 'prediction'})\n",
    "\n",
    "    sample_submission.to_csv(sample_submission_csv_path, index=False)\n",
    "\n",
    "gen_pred_csv_from_trained_model(\n",
    "    model=xgb_model,\n",
    "    X_test=X_test_submission_concatinated,\n",
    "    test_csv_path='data/test.csv',\n",
    "    sample_submission_csv_path='data/sample_submission.csv',\n",
    "    columns_to_drop=['date_forecast', 'date_calc', 'elevation:m', 'snow_density:kgm3', 'snow_drift:idx']\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
