{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
<<<<<<< Updated upstream
     "end_time": "2023-11-01T08:16:53.164847700Z",
     "start_time": "2023-11-01T08:16:49.428207600Z"
=======
<<<<<<< HEAD
     "end_time": "2023-11-02T10:33:00.518826100Z",
     "start_time": "2023-11-02T10:32:57.459427900Z"
=======
     "end_time": "2023-11-01T08:16:53.164847700Z",
     "start_time": "2023-11-01T08:16:49.428207600Z"
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\Desktop\\NTNU\\ML\\Testing\\utils.py:98: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_hourly = df.resample('H').mean()\n",
      "C:\\Users\\marku\\Desktop\\NTNU\\ML\\Testing\\utils.py:98: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_hourly = df.resample('H').mean()\n"
     ]
    }
   ],
   "source": [
    "train_a = pd.read_parquet('./data/A/train_targets.parquet')\n",
    "\n",
    "X_train_estimated_a = pd.read_parquet('./data/A/X_train_estimated.parquet')\n",
    "X_train_observed_a = pd.read_parquet('./data/A/X_train_observed.parquet')\n",
    "X_test_estimated_a = pd.read_parquet('./data/A/X_test_estimated.parquet')\n",
    "\n",
    "df = pd.concat([X_train_observed_a, X_train_estimated_a])\n",
    "\n",
    "df = resample_to_hourly(df)\n",
    "X_test_estimated_a = resample_to_hourly(X_test_estimated_a)\n",
    "\n",
    "df = pd.merge(df, train_a, left_on='date_forecast', right_on='time', how='inner')\n",
    "df = df.drop(columns=['snow_density:kgm3', 'snow_drift:idx', 'fresh_snow_1h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'fresh_snow_12h:cm', 'snow_melt_10min:mm', 'elevation:m', 'prob_rime:p', 'dew_or_rime:idx'])\n",
    "X_test_estimated_a = X_test_estimated_a.drop(columns=['snow_density:kgm3', 'snow_drift:idx', 'fresh_snow_1h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'fresh_snow_12h:cm', 'snow_melt_10min:mm', 'elevation:m', 'prob_rime:p', 'dew_or_rime:idx'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< Updated upstream
     "end_time": "2023-11-01T08:16:53.468557300Z",
     "start_time": "2023-11-01T08:16:53.170848500Z"
=======
<<<<<<< HEAD
     "end_time": "2023-11-02T10:33:00.830311200Z",
     "start_time": "2023-11-02T10:33:00.521826200Z"
=======
     "end_time": "2023-11-01T08:16:53.468557300Z",
     "start_time": "2023-11-01T08:16:53.170848500Z"
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
    }
   },
   "id": "7dddf00518babb04"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "cols_to_impute = ['ceiling_height_agl:m', 'cloud_base_agl:m']\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "X_test_estimated_a[cols_to_impute] = imputer.fit_transform(X_test_estimated_a[cols_to_impute])\n",
    "df[cols_to_impute] = imputer.fit_transform(df[cols_to_impute])\n",
    "df = df.dropna(subset=['pv_measurement'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< Updated upstream
     "end_time": "2023-11-01T08:16:53.513557Z",
     "start_time": "2023-11-01T08:16:53.468557300Z"
=======
<<<<<<< HEAD
     "end_time": "2023-11-02T10:33:00.891736200Z",
     "start_time": "2023-11-02T10:33:00.830311200Z"
=======
     "end_time": "2023-11-01T08:16:53.513557Z",
     "start_time": "2023-11-01T08:16:53.468557300Z"
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
    }
   },
   "id": "5b09941030a46e5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = is_estimated(df)\n",
    "df = generate_solar_features_1(df)\n",
    "\n",
    "X_test_estimated_a = is_estimated(X_test_estimated_a, 'date_forecast')\n",
    "X_test_estimated_a = generate_solar_features_1(X_test_estimated_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< Updated upstream
     "end_time": "2023-11-01T08:16:53.766212500Z",
     "start_time": "2023-11-01T08:16:53.516557600Z"
=======
<<<<<<< HEAD
     "end_time": "2023-11-02T10:33:01.116293400Z",
     "start_time": "2023-11-02T10:33:00.862727500Z"
=======
     "end_time": "2023-11-01T08:16:53.766212500Z",
     "start_time": "2023-11-01T08:16:53.516557600Z"
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
    }
   },
   "id": "575c134f04b12ffd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_end_date = '2022-10-21'\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "train_df = df[df['time'] < train_end_date]\n",
    "remaining_data = df[df['time'] > train_end_date]\n",
    "\n",
    "train_data, validation_df = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
    "train_df = pd.concat([train_df, train_data], ignore_index=True)\n",
    "\n",
    "# Identifying the features and the target variable\n",
    "X_train = train_df.drop(columns=['pv_measurement', 'time', 'date_forecast'])\n",
    "y_train = train_df['pv_measurement']\n",
    "X_val = validation_df.drop(columns=['pv_measurement', 'time', 'date_forecast'])\n",
    "y_val = validation_df['pv_measurement']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< Updated upstream
     "end_time": "2023-11-01T08:16:53.938808200Z",
     "start_time": "2023-11-01T08:16:53.768212900Z"
=======
<<<<<<< HEAD
     "end_time": "2023-11-02T10:33:01.273226900Z",
     "start_time": "2023-11-02T10:33:01.119295200Z"
=======
     "end_time": "2023-11-01T08:16:53.938808200Z",
     "start_time": "2023-11-01T08:16:53.768212900Z"
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
    }
   },
   "id": "735c00d28fb45964"
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": null,
<<<<<<< Updated upstream
=======
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_081653\\\"\n",
=======
<<<<<<< HEAD
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231102_103301\\\"\n",
=======
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231101_081653\\\"\n",
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (31863 samples, 109.86 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
<<<<<<< Updated upstream
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_081653\\\"\n",
=======
<<<<<<< HEAD
      "AutoGluon will save models to \"AutogluonModels\\ag-20231102_103301\\\"\n",
=======
      "AutoGluon will save models to \"AutogluonModels\\ag-20231101_081653\\\"\n",
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
<<<<<<< Updated upstream
      "Disk Space Avail:   946.53 GB / 2047.46 GB (46.2%)\n",
=======
<<<<<<< HEAD
      "Disk Space Avail:   977.72 GB / 2047.46 GB (47.8%)\n",
=======
      "Disk Space Avail:   946.53 GB / 2047.46 GB (46.2%)\n",
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
      "Train Data Rows:    31863\n",
      "Train Data Columns: 859\n",
      "Tuning Data Rows:    2197\n",
      "Tuning Data Columns: 859\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 649.75117, 1177.67732)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
<<<<<<< Updated upstream
      "\tAvailable Memory:                    52708.25 MB\n",
=======
<<<<<<< HEAD
      "\tAvailable Memory:                    51901.22 MB\n",
=======
      "\tAvailable Memory:                    52708.25 MB\n",
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
      "\tTrain Data (Original)  Memory Usage: 117.17 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 858 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :   1 | ['is_estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 858 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :   1 | ['is_estimated']\n",
      "\t1.9s = Fit runtime\n",
      "\t859 features in original data used to generate 859 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 116.93 MB (0.2% of available memory)\n",
<<<<<<< Updated upstream
      "Data preprocessing and feature engineering runtime = 2.15s ...\n",
=======
<<<<<<< HEAD
      "Data preprocessing and feature engineering runtime = 2.13s ...\n",
=======
      "Data preprocessing and feature engineering runtime = 2.15s ...\n",
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-152.7299\t = Validation score   (-mean_absolute_error)\n",
<<<<<<< Updated upstream
=======
<<<<<<< HEAD
      "\t3.62s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-153.3907\t = Validation score   (-mean_absolute_error)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
=======
>>>>>>> Stashed changes
      "\t3.58s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-153.3907\t = Validation score   (-mean_absolute_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
<<<<<<< Updated upstream
=======
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 94.0947\n",
      "[2000]\tvalid_set's l1: 90.9007\n",
      "[3000]\tvalid_set's l1: 89.7331\n",
      "[4000]\tvalid_set's l1: 89.1377\n",
      "[5000]\tvalid_set's l1: 88.8309\n",
      "[6000]\tvalid_set's l1: 88.7296\n",
      "[7000]\tvalid_set's l1: 88.6401\n",
<<<<<<< Updated upstream
      "[8000]\tvalid_set's l1: 88.5747\n"
=======
<<<<<<< HEAD
      "[8000]\tvalid_set's l1: 88.5747\n",
      "[9000]\tvalid_set's l1: 88.4477\n",
      "[10000]\tvalid_set's l1: 88.3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-88.3335\t = Validation score   (-mean_absolute_error)\n",
      "\t100.86s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 95.1734\n",
      "[2000]\tvalid_set's l1: 93.2164\n",
      "[3000]\tvalid_set's l1: 92.7358\n",
      "[4000]\tvalid_set's l1: 92.5886\n",
      "[5000]\tvalid_set's l1: 92.4035\n",
      "[6000]\tvalid_set's l1: 92.2893\n",
      "[7000]\tvalid_set's l1: 92.2514\n",
      "[8000]\tvalid_set's l1: 92.2207\n",
      "[9000]\tvalid_set's l1: 92.2271\n",
      "[10000]\tvalid_set's l1: 92.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-92.2191\t = Validation score   (-mean_absolute_error)\n",
      "\t149.8s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-106.3874\t = Validation score   (-mean_absolute_error)\n",
      "\t601.54s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-95.4077\t = Validation score   (-mean_absolute_error)\n",
      "\t594.7s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-104.7218\t = Validation score   (-mean_absolute_error)\n",
      "\t91.1s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-107.9299\t = Validation score   (-mean_absolute_error)\n",
      "\t44.6s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-99.4111\t = Validation score   (-mean_absolute_error)\n",
      "\t31.43s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-89.0747\t = Validation score   (-mean_absolute_error)\n",
      "\t103.04s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 94.7572\n",
      "[2000]\tvalid_set's l1: 94.1652\n",
      "[3000]\tvalid_set's l1: 94.105\n",
      "[4000]\tvalid_set's l1: 94.0865\n",
      "[5000]\tvalid_set's l1: 94.08\n",
      "[6000]\tvalid_set's l1: 94.0778\n",
      "[7000]\tvalid_set's l1: 94.0771\n",
      "[8000]\tvalid_set's l1: 94.0768\n",
      "[9000]\tvalid_set's l1: 94.0767\n",
      "[10000]\tvalid_set's l1: 94.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-94.0767\t = Validation score   (-mean_absolute_error)\n",
      "\t461.79s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-84.527\t = Validation score   (-mean_absolute_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2190.98s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231102_103301\\\")\n"
=======
      "[8000]\tvalid_set's l1: 88.5747\n"
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# Combine training and validation data into a single dataset for AutoGluon\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "# Specify the name of the target variable\n",
    "label = 'pv_measurement'\n",
    "\n",
    "# Create a TabularPredictor object\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"mean_absolute_error\").fit(train_data=train_data, tuning_data=val_data, presets='medium_quality')"
   ],
<<<<<<< Updated upstream
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-01T08:16:53.941807800Z"
    }
   },
   "id": "8cdc01fdb2478458"
=======
   "metadata": {
    "collapsed": false,
<<<<<<< HEAD
    "ExecuteTime": {
     "end_time": "2023-11-02T11:09:32.339991Z",
     "start_time": "2023-11-02T10:33:01.274228300Z"
=======
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-01T08:16:53.941807800Z"
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
    }
   },
   "id": "8cdc01fdb2478458"
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -84.526975       0.633603  353.920923                0.001000           0.213365            2       True         12\n",
      "1            LightGBMXT  -88.333488       0.112520  100.864453                0.112520         100.864453            1       True          3\n",
      "2        NeuralNetTorch  -89.074721       0.410561  103.038139                0.410561         103.038139            1       True         10\n",
      "3              LightGBM  -92.219139       0.109522  149.804965                0.109522         149.804965            1       True          4\n",
      "4         LightGBMLarge  -94.076696       0.306142  461.792318                0.306142         461.792318            1       True         11\n",
      "5              CatBoost  -95.407715       0.030508  594.702344                0.030508         594.702344            1       True          6\n",
      "6               XGBoost  -99.411094       0.056513   31.433232                0.056513          31.433232            1       True          9\n",
      "7         ExtraTreesMSE -104.721836       0.046000   91.097630                0.046000          91.097630            1       True          7\n",
      "8       RandomForestMSE -106.387434       0.062536  601.537685                0.062536         601.537685            1       True          5\n",
      "9       NeuralNetFastAI -107.929871       0.057004   44.598164                0.057004          44.598164            1       True          8\n",
      "10       KNeighborsUnif -152.729857       0.593547    3.616638                0.593547           3.616638            1       True          1\n",
      "11       KNeighborsDist -153.390743       0.553940    0.609697                0.553940           0.609697            1       True          2\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'RFModel', 'LGBModel', 'CatBoostModel', 'XGBoostModel', 'KNNModel', 'NNFastAiTabularModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'XTModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 858 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "('int', ['bool']) :   1 | ['is_estimated']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\Desktop\\Envs\\MLenv\\lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "outputs": [],
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
   "source": [
    "results = predictor.fit_summary()"
   ],
   "metadata": {
    "collapsed": false,
<<<<<<< HEAD
    "ExecuteTime": {
     "end_time": "2023-11-02T11:09:33.692244800Z",
     "start_time": "2023-11-02T11:09:32.340657800Z"
    }
=======
    "is_executing": true
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
   },
   "id": "a7e2c6b4f360233f"
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 859 features using 2197 rows with 5 shuffle sets...\n",
      "\t3571.22s\t= Expected runtime (714.24s per shuffle set)\n",
      "\t1692.01s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "feature_importance = predictor.feature_importance(val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:37:45.870803Z",
     "start_time": "2023-11-02T11:09:33.694245500Z"
    }
   },
   "id": "3dbb170298a077b4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231102_113745\\\"\n",
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (31863 samples, 67.68 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231102_113745\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   976.31 GB / 2047.46 GB (47.7%)\n",
      "Train Data Rows:    31863\n",
      "Train Data Columns: 529\n",
      "Tuning Data Rows:    2197\n",
      "Tuning Data Columns: 529\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 649.75117, 1177.67732)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    56367.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 72.07 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 529 | ['direct_rad:W_plus_diffuse_rad:W', 'direct_rad:W_times_sun_elevation:d', 'direct_rad:W_times_clear_sky_rad:W', 'direct_rad:W_plus_sun_elevation:d', 'direct_rad:W_plus_clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 529 | ['direct_rad:W_plus_diffuse_rad:W', 'direct_rad:W_times_sun_elevation:d', 'direct_rad:W_times_clear_sky_rad:W', 'direct_rad:W_plus_sun_elevation:d', 'direct_rad:W_plus_clear_sky_rad:W', ...]\n",
      "\t1.0s = Fit runtime\n",
      "\t529 features in original data used to generate 529 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 72.07 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-156.9257\t = Validation score   (-mean_absolute_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-157.3448\t = Validation score   (-mean_absolute_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 94.8094\n",
      "[2000]\tvalid_set's l1: 91.1564\n",
      "[3000]\tvalid_set's l1: 89.6507\n",
      "[4000]\tvalid_set's l1: 89.0496\n",
      "[5000]\tvalid_set's l1: 88.6239\n",
      "[6000]\tvalid_set's l1: 88.4249\n",
      "[7000]\tvalid_set's l1: 88.142\n",
      "[8000]\tvalid_set's l1: 87.9455\n",
      "[9000]\tvalid_set's l1: 87.8285\n",
      "[10000]\tvalid_set's l1: 87.6959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-87.6948\t = Validation score   (-mean_absolute_error)\n",
      "\t110.38s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 93.4136\n",
      "[2000]\tvalid_set's l1: 92.0652\n",
      "[3000]\tvalid_set's l1: 91.7453\n",
      "[4000]\tvalid_set's l1: 91.4531\n",
      "[5000]\tvalid_set's l1: 91.3031\n",
      "[6000]\tvalid_set's l1: 91.2216\n",
      "[7000]\tvalid_set's l1: 91.174\n",
      "[8000]\tvalid_set's l1: 91.1615\n",
      "[9000]\tvalid_set's l1: 91.1432\n",
      "[10000]\tvalid_set's l1: 91.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-91.1321\t = Validation score   (-mean_absolute_error)\n",
      "\t154.4s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-105.971\t = Validation score   (-mean_absolute_error)\n",
      "\t625.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-92.205\t = Validation score   (-mean_absolute_error)\n",
      "\t522.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-104.6491\t = Validation score   (-mean_absolute_error)\n",
      "\t115.41s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-111.421\t = Validation score   (-mean_absolute_error)\n",
      "\t41.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-94.3357\t = Validation score   (-mean_absolute_error)\n",
      "\t584.52s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-92.247\t = Validation score   (-mean_absolute_error)\n",
      "\t89.44s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 94.1835\n",
      "[2000]\tvalid_set's l1: 93.418\n",
      "[3000]\tvalid_set's l1: 93.2886\n",
      "[4000]\tvalid_set's l1: 93.2495\n",
      "[5000]\tvalid_set's l1: 93.2393\n",
      "[6000]\tvalid_set's l1: 93.2345\n",
      "[7000]\tvalid_set's l1: 93.2334\n",
      "[8000]\tvalid_set's l1: 93.233\n",
      "[9000]\tvalid_set's l1: 93.2328\n",
      "[10000]\tvalid_set's l1: 93.2328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-93.2328\t = Validation score   (-mean_absolute_error)\n",
      "\t426.38s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-85.379\t = Validation score   (-mean_absolute_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2678.07s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231102_113745\\\")\n"
     ]
    }
   ],
   "source": [
    "best_features = feature_importance[feature_importance['importance'] > 0.1].index.tolist()\n",
    "\n",
    "X_train = X_train[best_features]\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "X_val = X_val[best_features]\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "label = 'pv_measurement'\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"mean_absolute_error\").fit(train_data=train_data, tuning_data=val_data, presets='medium_quality')\n",
    "# , num_gpus=1, num_stack_levels=0, use_bag_holdout=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:22:24.091556900Z",
     "start_time": "2023-11-02T11:37:45.877803100Z"
    }
   },
   "id": "8c65ac4e4ba744ed"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model   score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -85.379029       0.905469  1461.495881                0.000000           0.192523            2       True         12\n",
      "1            LightGBMXT  -87.694764       0.177644   110.375663                0.177644         110.375663            1       True          3\n",
      "2              LightGBM  -91.132115       0.206001   154.399794                0.206001         154.399794            1       True          4\n",
      "3              CatBoost  -92.205027       0.016004   522.564111                0.016004         522.564111            1       True          6\n",
      "4        NeuralNetTorch  -92.247037       0.242364    89.439373                0.242364          89.439373            1       True         10\n",
      "5         LightGBMLarge  -93.232782       0.474243   426.382002                0.474243         426.382002            1       True         11\n",
      "6               XGBoost  -94.335717       0.263457   584.524417                0.263457         584.524417            1       True          9\n",
      "7         ExtraTreesMSE -104.649052       0.046417   115.406401                0.046417         115.406401            1       True          7\n",
      "8       RandomForestMSE -105.970954       0.046675   625.496901                0.046675         625.496901            1       True          5\n",
      "9       NeuralNetFastAI -111.421040       0.038000    41.603759                0.038000          41.603759            1       True          8\n",
      "10       KNeighborsUnif -156.925679       0.481657     0.324742                0.481657           0.324742            1       True          1\n",
      "11       KNeighborsDist -157.344813       0.607668     0.345633                0.607668           0.345633            1       True          2\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'RFModel', 'LGBModel', 'CatBoostModel', 'XGBoostModel', 'KNNModel', 'NNFastAiTabularModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'XTModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 529 | ['direct_rad:W_plus_diffuse_rad:W', 'direct_rad:W_times_sun_elevation:d', 'direct_rad:W_times_clear_sky_rad:W', 'direct_rad:W_plus_sun_elevation:d', 'direct_rad:W_plus_clear_sky_rad:W', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marku\\Desktop\\Envs\\MLenv\\lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:22:25.482532900Z",
     "start_time": "2023-11-02T12:22:24.092556200Z"
    }
   },
   "id": "da1b59d1af607f52"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
=======
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importance = predictor.feature_importance(val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3dbb170298a077b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_features = feature_importance[feature_importance['importance'] > 0.1].index.tolist()\n",
    "\n",
    "X_train = X_train[best_features]\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "X_val = X_val[best_features]\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "label = 'pv_measurement'\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"mean_absolute_error\").fit(train_data=train_data, tuning_data=val_data, presets='medium_quality')\n",
    "# , num_gpus=1, num_stack_levels=0, use_bag_holdout=True"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8c65ac4e4ba744ed"
>>>>>>> Stashed changes
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = predictor.fit_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
<<<<<<< Updated upstream
   "id": "a7e2c6b4f360233f"
=======
   "id": "da1b59d1af607f52"
>>>>>>> Stashed changes
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "feature_importance = predictor.feature_importance(val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3dbb170298a077b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_features = feature_importance[feature_importance['importance'] > 0.1].index.tolist()\n",
    "\n",
    "X_train = X_train[best_features]\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "X_val = X_val[best_features]\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "label = 'pv_measurement'\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"mean_absolute_error\").fit(train_data=train_data, tuning_data=val_data, presets='medium_quality')\n",
    "# , num_gpus=1, num_stack_levels=0, use_bag_holdout=True"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8c65ac4e4ba744ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = predictor.fit_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "da1b59d1af607f52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
=======
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
    "X_test_estimated_a = X_test_estimated_a[best_features]\n",
    "\n",
    "y_pred = predictor.predict(X_test_estimated_a)\n",
    "y_pred = y_pred.clip(lower=0)\n",
    "y_pred = y_pred.reset_index(drop=True)\n",
    "y_pred.index.name = 'id'"
   ],
   "metadata": {
    "collapsed": false,
<<<<<<< Updated upstream
    "is_executing": true
=======
<<<<<<< HEAD
    "ExecuteTime": {
     "end_time": "2023-11-02T12:22:26.424831500Z",
     "start_time": "2023-11-02T12:22:25.484532300Z"
    }
=======
    "is_executing": true
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
   },
   "id": "bfe3dfacd845e4c5"
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
=======
<<<<<<< HEAD
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
    "df.to_csv('result_a.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:22:26.457619700Z",
     "start_time": "2023-11-02T12:22:26.426102400Z"
    }
   },
   "id": "648334688fa703c3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T12:22:26.470627800Z",
     "start_time": "2023-11-02T12:22:26.455115700Z"
    }
   },
   "id": "3028bea999a386f0"
=======
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
>>>>>>> Stashed changes
    "df.to_csv('result_a_1h_forward_medium.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "648334688fa703c3"
<<<<<<< Updated upstream
=======
>>>>>>> 028be193bb93851644643d37e569407714f84c6c
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
