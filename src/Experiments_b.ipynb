{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from utils import *\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_b = pd.read_parquet('./data/B/train_targets.parquet')\n",
    "\n",
    "X_train_estimated_b = pd.read_parquet('./data/B/X_train_estimated.parquet')\n",
    "X_train_observed_b = pd.read_parquet('./data/B/X_train_observed.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('./data/B/X_test_estimated.parquet')\n",
    "\n",
    "df = pd.concat([X_train_observed_b, X_train_estimated_b])\n",
    "\n",
    "df = resample_to_hourly(df)\n",
    "X_test_estimated_b = resample_to_hourly(X_test_estimated_b)\n",
    "\n",
    "df = pd.merge(df, train_b, left_on='date_forecast', right_on='time', how='inner')\n",
    "df = df.drop(columns=['snow_density:kgm3', 'elevation:m'])\n",
    "X_test_estimated_b = X_test_estimated_b.drop(columns=['snow_density:kgm3', 'elevation:m'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac00ca6f300a78e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols_to_impute = ['ceiling_height_agl:m', 'cloud_base_agl:m']\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "X_test_estimated_b[cols_to_impute] = imputer.fit_transform(X_test_estimated_b[cols_to_impute])\n",
    "df[cols_to_impute] = imputer.fit_transform(df[cols_to_impute])\n",
    "df = df.dropna(subset=['pv_measurement'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8fcdf3064ae41f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments = find_long_constant_periods(train_b['pv_measurement'], threshold=5)\n",
    "df = remove_constant_periods(df, segments)\n",
    "df = remove_unwanted_rows(df)\n",
    "df = is_estimated(df)\n",
    "df = generate_solar_features_2(df)\n",
    "\n",
    "X_test_estimated_b = is_estimated(X_test_estimated_b, 'date_forecast')\n",
    "X_test_estimated_b = generate_solar_features_2(X_test_estimated_b)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "247b82798133aca5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_end_date = '2022-10-21'\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "train_df = df[df['time'] < train_end_date]\n",
    "remaining_data = df[df['time'] > train_end_date]\n",
    "\n",
    "train_data, validation_df = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
    "train_df = pd.concat([train_df, train_data], ignore_index=True)\n",
    "\n",
    "# Identifying the features and the target variable\n",
    "X_train = train_df.drop(columns=['pv_measurement', 'time', 'date_forecast'])\n",
    "y_train = train_df['pv_measurement']\n",
    "X_val = validation_df.drop(columns=['pv_measurement', 'time', 'date_forecast'])\n",
    "y_val = validation_df['pv_measurement']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8657a912adc261ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine training and validation data into a single dataset for AutoGluon\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "# Specify the name of the target variable\n",
    "label = 'pv_measurement'\n",
    "\n",
    "# Create a TabularPredictor object\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"mean_absolute_error\").fit(train_data=train_data, tuning_data=val_data, presets='medium_quality')\n",
    "# , num_gpus=1, num_stack_levels=0, use_bag_holdout=True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ede6d9dd30e06e4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = predictor.fit_summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b9bf8230058988"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importance = predictor.feature_importance(val_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4239760461ae5776"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_features = feature_importance[feature_importance['importance'] > 0.2].index.tolist()\n",
    "\n",
    "X_train = X_train[best_features]\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "X_val = X_val[best_features]\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "label = 'pv_measurement'\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=\"mean_absolute_error\").fit(train_data=train_data, tuning_data=val_data, presets='medium_quality')\n",
    "# , num_gpus=1, num_stack_levels=0, use_bag_holdout=True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "340aac2e73a0c943"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = predictor.fit_summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "417550234d57c8ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_estimated_b = X_test_estimated_b[best_features]\n",
    "\n",
    "y_pred = predictor.predict(X_test_estimated_b)\n",
    "y_pred = y_pred.clip(lower=0)\n",
    "y_pred = y_pred.reset_index(drop=True)\n",
    "y_pred.index.name = 'id'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c04a66b06d0d305f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
    "df.to_csv('result_b.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83feb22b3b78fa75"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
