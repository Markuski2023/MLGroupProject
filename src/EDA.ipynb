{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "EDA guide: https://miykael.github.io/blog/2022/advanced_eda/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74d37579db0a659a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "# from tsfresh import extract_features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_targets = pd.read_parquet('./data/A/train_targets.parquet')\n",
    "X_test_estimated = pd.read_parquet('./data/A/X_test_estimated.parquet')\n",
    "X_train_estimated = pd.read_parquet('./data/A/X_train_estimated.parquet')\n",
    "X_train_observed = pd.read_parquet('./data/A/X_train_observed.parquet')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f56c390ae35f6f82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7247dc1e01c0fd16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_observed.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "538bd41993c5c387"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_estimated.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe9e77fa629ad842"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_targets.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0a5acec16b1c959"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From these to descriptions we can see that X_train_observed stops where X_train_estimated start. This gives us an intuition to concat the two datasets.\n",
    "\n",
    "We also see that the date_forecast feature contains values for each quarter of an hour. This needs to be fixed since train_targets only contain values for each hour."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb57e28f874406d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.concat([X_train_observed, X_train_estimated])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e48faaf4fde4597"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.merge(df, train_targets, left_on='date_forecast', right_on='time', how='inner')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eac2f343d1522f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merging the train_targets into df to make it easier with analysis later on. This also removed each value not containing a whole hour."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c62154092098944b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Datatypes and structure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53bcd48fcc057bb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.value_counts(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43aa8d75d5639fb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This shows that we have three datetime columns. Let's further explore what these are:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e08416247945de9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Non-numeric features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e824163004e1f3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude='number').head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "267af4a758c417a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this we can extract two major points of information: \n",
    "- First of all, we have 24hrs of data for just about each day in the dataset. \n",
    "- Secondly, after merging the X_train_observed, X_train_estimated and train_targets we now have these three datetime columns. From this we see: date_calc contain Nat values, date_forecast and time has the same values. These findings indicate that we can remove either time or date_forecast and have to look deeper into date_calc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b23aca9beed63aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['date_calc'].describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7f2fa9e1f916a03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "When describing the feature we can see that it has values for almost a year. This may indicate that something went wrong when either concating or merging the datasets. Let's investigate:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15c083d73c20f152"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_estimated[['date_forecast', 'date_calc']].head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "847cef26ab0936fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this we can see that date_calc indicates which day a forecast was calculated. Based on this, we can for now safely remove it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2ceaa580123ef5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['date_calc', 'date_forecast'])\n",
    "df.select_dtypes(exclude='number').head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71dd96812d81c799"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe(exclude='number')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ff5c5d07345a3b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have a total of 34.061 rows of data, ranging from the mid of June 2019 to the mid of April 2023"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82ccac5931f003f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Numeric features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6483f017b8743a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_values = df.select_dtypes(exclude='datetime').nunique().sort_values()\n",
    "unique_values.plot.bar(logy=True, figsize=(15, 4))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96009e3282ecd2d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this we can see that most features are continuous, but three of the features are single valued. This means that they only have one value across all rows. This is something we need to investigate further:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9709f531aefe395"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[['elevation:m', 'snow_density:kgm3', 'snow_drift:idx']].head(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee7bfa05e936a745"
  },
  {
   "cell_type": "markdown",
   "source": [
    "These features have major issues and can therefor be removed from the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5456aa1cba85c768"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['elevation:m', 'snow_density:kgm3', 'snow_drift:idx'], axis=1)\n",
    "pd.value_counts(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5124ad06842b788c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, we now have three less float32 features, meaning that the features was properly removed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8af26deb900928c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Quality check"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "940f48fe3ab3428e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13d493086b821f36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have a total of 7777 missing values in ceiling_height_agl:m and 3063 missing values in cloud_base_agl:m. There are too many missing values to remove the rows containing them, and we don't know the importance of the features yet, so we can't just remove them. Our only choice is then to impute them. A normal strategy for numeric features is using the mean of this feature:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c221b8ff9314229b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[['ceiling_height_agl:m', 'cloud_base_agl:m']] = imputer.fit_transform(df[['ceiling_height_agl:m', 'cloud_base_agl:m']])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45ea75ab137e88a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10440e7f2a4d5f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the null values is now removed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7431d802cbbf3386"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# REMEMBER TO FIND OUTLIERS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38cb98120db18f49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Shallow Feature Information\n",
    "Considering the dimensionality of the dataset, analyzing each feature independently is close to impossible. Therefor, we will first plot each feature and only comment those with some interesting values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2b7bab1721dc569"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Feature Distributions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a677896dad31d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop the index and target variable columns for feature distribution analysis\n",
    "X_observed = X_train_observed.drop(columns=['date_calc', 'date_forecast'])\n",
    "X_estimated = X_train_estimated.drop(columns=['date_calc', 'date_forecast'])\n",
    "def plot_grid_feature_distributions(observed_df, estimated_df):\n",
    "    features = observed_df.columns\n",
    "    num_features = len(features)\n",
    "    num_rows = -(-num_features // 5)  # Calculate rows needed, rounding up\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 5, figsize=(20, num_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the 2D array to 1D\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "        sns.histplot(observed_df[feature], kde=False, bins=50, color='b', label='Observed', stat='probability', ax=ax, element='step')\n",
    "        sns.histplot(estimated_df[feature], kde=False, bins=50, color='r', label='Estimated', stat='probability', ax=ax, element='step')\n",
    "        ax.set_title(f'{feature}')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Normalized Count')\n",
    "        ax.legend()\n",
    "    \n",
    "    # Remove extra subplots\n",
    "    for i in range(num_features, num_rows * 5):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the grid\n",
    "plot_grid_feature_distributions(X_observed, X_estimated)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ca350323a9abc1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "absolute_humidity_2m:gm3: Shows a bimodal distribution, indicating two distinct groups or conditions in the dataset.\n",
    "\n",
    "air_density_2m:kgm3: Almost normally distributed but has some outliers on the lower end.\n",
    "\n",
    "ceiling_height_agl:m: Highly skewed to the right, meaning most of the values are clustered at the lower end.\n",
    "\n",
    "clear_sky_energy_1h:J: Most values are zero, but there are some with higher values, indicating specific conditions where clear sky energy is non-zero.\n",
    "\n",
    "total_cloud_cover:p: The distribution is almost binary, with most values at either 0 or 100, indicating clear sky or full cloud cover.\n",
    "\n",
    "visibility:m: This feature also shows a bimodal distribution, indicating two different visibility conditions.\n",
    "\n",
    "pv_measurement: Highly skewed towards the left. Indicating, most of the time, the solar power consumption is very low."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9194006e68f77d22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Linear Correlations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7febd9837f2b9f06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4512f8cc2c63ed80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Highly Interdependent Features:\n",
    "pressure_50m:hPa, sfc_pressure:hPa, and pressure_100m:hPa: These features have correlations very close to 1, indicating they are almost identical. One or two of these could likely be removed without losing much information.\n",
    "\n",
    "dew_point_2m:K and absolute_humidity_2m:gm3: With a correlation of approximately 0.97, these variables are highly interrelated, suggesting redundancy.\n",
    "\n",
    "clear_sky_energy_1h:J and clear_sky_rad:W: These also have a very high correlation of approximately 0.99, indicating potential redundancy.\n",
    "\n",
    "Weather and Time-related Features:\n",
    "fresh_snow_24h:cm, fresh_snow_12h:cm, fresh_snow_6h:cm, fresh_snow_3h:cm, and fresh_snow_1h:cm: These features are highly correlated with each other, ranging from 0.78 to 0.95, indicating they carry similar information about snowfall over different time periods.\n",
    "\n",
    "solar_zenith_angle:d and sun_elevation:d: These features have a high negative correlation of -0.99, which makes sense because as the sun rises, the solar zenith angle decreases.\n",
    "\n",
    "Correlations with Target Variable (pv_measurement):\n",
    "clear_sky_energy_1h:J: This feature has a high positive correlation of 0.78 with the target variable 'pv_measurement', signifying its importance in predicting the target.\n",
    "\n",
    "sun_elevation:d: This feature also shows a high positive correlation of 0.76 with the target variable, indicating its relevance in predicting solar energy production.\n",
    "\n",
    "Other Interesting Correlations:\n",
    "air_density_2m:kgm3 and t_1000hPa:K: These features have a high negative correlation of -0.91, which is logical given the inverse relationship between air density and temperature."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8013aa67683fa901"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Non-linear Correlations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec91e726fd6438d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc58314dde1626c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Highly Interdependent Features:\n",
    "pressure_50m:hPa, sfc_pressure:hPa, and pressure_100m:hPa: These features have near-perfect Spearman correlations, suggesting they convey almost identical information. Consider dropping some to remove redundancy.\n",
    "\n",
    "dew_point_2m:K and absolute_humidity_2m:gm3: With a Spearman correlation of around 0.97, these features are highly associated and possibly redundant.\n",
    "\n",
    "clear_sky_energy_1h:J and clear_sky_rad:W: These have a Spearman correlation of around 0.99, further confirming their redundancy.\n",
    "\n",
    "Weather and Time-related Features:\n",
    "fresh_snow_24h:cm, fresh_snow_12h:cm, fresh_snow_6h:cm, fresh_snow_3h:cm, and fresh_snow_1h:cm: These features show high Spearman correlations ranging from 0.75 to 0.94, indicating they are capturing similar snowfall patterns over different time frames.\n",
    "\n",
    "solar_zenith_angle:d and sun_elevation:d: Their Spearman correlation is -0.99, which is in line with their natural inverse relationship.\n",
    "\n",
    "Correlations with Target Variable (pv_measurement):\n",
    "    clear_sky_energy_1h:J: This has a Spearman correlation of 0.78 with the target variable, emphasizing its importance for prediction.\n",
    "\n",
    "sun_elevation:d: This feature also has a Spearman correlation of 0.76 with the target variable, underlining its significance.\n",
    "\n",
    "Other Interesting Correlations:\n",
    "air_density_2m:kgm3 and t_1000hPa:K: These features have a Spearman correlation of -0.91, suggesting a robust inverse relationship even when accounting for non-linearities."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aba8075ce1c06b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 Correlations Based on Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed9c991a72cfbca7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "787b07a3a9a14211"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5 First Feature Extraction Based on Feature Redundancy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "686c043bb1471398"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 In-depth Feature Information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6268e30d3b0ebefc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Feature Extraction for Further EDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19265e014fc8bec4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = df.drop(columns=['pv_measurement', 'time'])  # Drop the index, target, and time columns\n",
    "y = df['pv_measurement']  # Target variable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa492c00e2c9ee36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1.1 Using XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18b56461ef1bfc07"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize and fit the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "# Pair feature names with their importance scores\n",
    "feature_importance_dict = dict(zip(X.columns, feature_importances))\n",
    "\n",
    "# Sort the features by importance\n",
    "sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract the top 20 most important features\n",
    "top_20_features = sorted_features[:20]\n",
    "\n",
    "# Plotting the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh([x[0] for x in reversed(top_20_features)], [x[1] for x in reversed(top_20_features)])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Most Important Features According to XGBoost')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "835a09ab0514fcd2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1.2 Using Mutual Information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e44eef95c6788f19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mi = mutual_info_regression(X, y)\n",
    "mi_series = pd.Series(mi, index=X.columns)\n",
    "mi_series.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# Top 20 features based on Mutual Information\n",
    "top_20_mi = mi_series[:20]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(top_20_mi.index, top_20_mi.values)\n",
    "plt.xlabel('Mutual Information')\n",
    "plt.title('Top 20 Most Important Features According to Mutual Information')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a26d2cac4673c61a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1.3 Using Recursive Feature Elimination"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb5fc7d91d6b7895"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimator = xgb.XGBRegressor()\n",
    "selector = RFE(estimator, n_features_to_select=20, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "top_20_rfe = pd.Series(selector.support_, index=X.columns)\n",
    "top_20_rfe = top_20_rfe[top_20_rfe].index\n",
    "\n",
    "# Plotting the top 20 most important features according to RFE\n",
    "top_20_rfe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a641b9f835eb2e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1.4 Using F-Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af973f821946c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "F_values, p_values = f_regression(X, y)\n",
    "f_reg_series = pd.Series(F_values, index=X.columns)\n",
    "f_reg_series.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# Top 20 features based on F-Regression\n",
    "top_20_f_reg = f_reg_series[:20]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(top_20_f_reg.index, top_20_f_reg.values)\n",
    "plt.xlabel('F-Value')\n",
    "plt.title('Top 20 Most Important Features According to F-Regression')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11bbbf5f874ab5d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Seasonal Decomposition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb06fa9b634c43fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68fa7b50b2e97c2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 Stationarity "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e64620e4aff1056b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "923b8157b9d87711"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.4 Autocorrelation (ACF/PACF)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f260b4803c7d358b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "730c256a40098232"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Feature Engineering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0719870de24dba4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 Time based Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3383993dbf8f507"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def date_features(df):\n",
    "    df['hour'] = pd.to_datetime(df['time']).dt.hour\n",
    "    df['day'] = pd.to_datetime(df['time']).dt.dayofyear\n",
    "    df['month'] = pd.to_datetime(df['time']).dt.month\n",
    "    df['quarter'] = pd.to_datetime(df['time']).dt.quarter\n",
    "\n",
    "    df['lagged_pv_measurement_1h'] = df['pv_measurement'].shift(1)\n",
    "    df['lagged_pv_measurement_3h'] = df['pv_measurement'].shift(3)\n",
    "    df['lagged_pv_measurement_6h'] = df['pv_measurement'].shift(6)\n",
    "\n",
    "    df['rolling_mean_pv_measurement_3h'] = df['pv_measurement'].rolling(window=3).mean()\n",
    "    return df\n",
    "\n",
    "date_features(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90750a2cad8120b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make sure to have a column 'id' for each time series and 'time' for the time stamps\n",
    "# extracted_features = extract_features(df, column_id='id', column_sort='time')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9673a6eee613355f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
